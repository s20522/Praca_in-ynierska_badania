#  Przewodnik po Eksperymentach z Sieciami Neuronowymi (MLP)

**Autor:** Heart Failure Research Team  
**Data:** 29 grudnia 2024  
**Cel:** Wyjanienie, jak systematycznie budowa i optymalizowa sie neuronow (MLP) oraz por贸wnanie jej wynik贸w z modelem Random Forest.

---

## Wprowadzenie: Czym jest Sie Neuronowa (MLP)?

Wyobra藕 sobie sie neuronow jako **m贸zg do wynajcia**. Skada si ona z poczonych ze sob "neuron贸w" uo偶onych w warstwy. Ka偶dy neuron to prosty kalkulator, kt贸ry odbiera sygnay od innych, przetwarza je i wysya dalej. Uczc sie, pokazujemy jej tysice przykad贸w, a ona sama dostosowuje si pocze midzy neuronami, aby nauczy si rozpoznawa skomplikowane wzorce.

**Wielowarstwowy Perceptron (MLP)** to najpopularniejszy typ takiej sieci. Jest jak uniwersalny scyzoryk - potrafi nauczy si niemal ka偶dej zale偶noci w danych, jeli jest odpowiednio du偶y i dobrze wytrenowany. W medycynie mo偶e odkry ukryte, nieliniowe zwizki midzy danymi pacjenta a ryzykiem choroby, kt贸rych prostsze modele by nie zauwa偶yy.

### Dlaczego to robimy?

- **Aby znale藕 zo偶one wzorce:** Sieci neuronowe potrafi modelowa bardzo skomplikowane, nieliniowe zale偶noci, kt贸re s poza zasigiem wielu klasycznych modeli.
- **Aby sprawdzi alternatyw:** Chcemy zobaczy, czy inne, bardziej elastyczne podejcie da lepsze wyniki ni偶 sprawdzony Random Forest.
- **Aby zbada wpyw hiperparametr贸w:** Chcemy zrozumie, jak architektura, funkcje aktywacji czy regularyzacja wpywaj na dziaanie sieci.

---

## Punkt Odniesienia: Model Random Forest

Naszym mistrzem do pokonania jest model Random Forest z poprzednich etap贸w. To do jego wynik贸w bdziemy por贸wnywa nasze sieci neuronowe.

**Wyniki modelu Random Forest (Baseline):**

| Metryka | Warto |
|---|---|
| **F1-score** | **0.6800** |
| **Recall (Czuo)** | **0.8947** |
| **Precision (Precyzja)** | 0.5484 |
| **AUC-ROC** | 0.7689 |

Czy "m贸zg do wynajcia" (MLP) pokona "mdro tumu" (Random Forest)? Zobaczmy!

---

## Seria Eksperyment贸w: Krok po Kroku do Najlepszego Modelu

Zbudowanie dobrej sieci neuronowej to proces. Przeprowadzilimy seri kontrolowanych eksperyment贸w, aby znale藕 optymaln konfiguracj.

### Eksperyment 1: Jaki rozmiar m贸zgu? (Architektura)

Sprawdzilimy, jak liczba warstw i neuron贸w wpywa na wyniki. Testowalimy sieci od "pytkich" (1 warstwa) do "gbokich" (3 warstwy).

![Por贸wnanie architektur](results/nn_fig_01_architecture_comparison.png)

> **Rysunek 1.** Por贸wnanie metryk dla r贸偶nych architektur. Najlepsze wyniki (zwaszcza F1-score i Recall) osigna architektura `Shallow_128` (jedna warstwa ze 128 neuronami).

**Wnioski:**
- **Gbiej nie znaczy lepiej:** Najgbsze sieci (`Deep_...`) miay jedne z gorszych wynik贸w. Prawdopodobnie byy zbyt skomplikowane dla tak maego zbioru danych i zaczynay si przeucza.
- **Optymalny rozmiar:** Najlepszy kompromis midzy zo偶onoci a skutecznoci osigna stosunkowo prosta, ale szeroka sie z jedn warstw 128 neuron贸w.

### Eksperyment 2: Jak neurony "myl"? (Funkcje Aktywacji)

Funkcja aktywacji decyduje, czy i jak silnie neuron ma "zareagowa". Por贸wnalimy trzy najpopularniejsze: `ReLU`, `LeakyReLU` i `ELU`.

![Por贸wnanie funkcji aktywacji](results/nn_fig_02_activation_comparison.png)

> **Rysunek 2.** Por贸wnanie metryk dla r贸偶nych funkcji aktywacji. `ELU` i `ReLU` day bardzo zbli偶one, dobre wyniki, podczas gdy `LeakyReLU` wypada nieco sabiej.

**Wnioski:**
- **ELU i ReLU na czele:** Obie te funkcje okazay si bardzo skuteczne. `ELU` daa minimalnie lepszy F1-score i AUC, co mo偶e sugerowa, 偶e jej zdolno do obsugi ujemnych wartoci bya w tym przypadku korzystna.
- **Wyb贸r nie jest krytyczny:** R贸偶nice nie byy drastyczne, co pokazuje, 偶e dla tego problemu wyb贸r midzy `ReLU` a `ELU` nie jest kluczow decyzj.

### Eksperyment 3 i 4: Jak powstrzyma "kujona"? (Regularyzacja)

Sieci neuronowe, jak pilny ucze, mog nauczy si danych treningowych na pami (przeuczenie, overfitting), ale potem sabo radz sobie z nowymi danymi. Regularyzacja to techniki, kt贸re zmuszaj sie do uog贸lniania wiedzy. Sprawdzilimy dwie metody: **Dropout** (losowe wyczanie neuron贸w) i **L2** (karanie za zbyt du偶e wagi).

![Wpyw Dropout](results/nn_fig_03_dropout_effect.png)

> **Rysunek 3.** Wpyw wsp贸czynnika Dropout. Najlepszy F1-score (0.6047) i AUC (0.7689) uzyskano przy `Dropout=0.5`, co sugeruje, 偶e silna regularyzacja bya potrzebna.

![Wpyw L2](results/nn_fig_04_l2_effect.png)

> **Rysunek 4.** Wpyw regularyzacji L2. Najlepszy F1-score (0.6222) uzyskano przy `L2=0.001`. Zbyt du偶a warto (`L2=0.1`) drastycznie obni偶ya Recall, poniewa偶 model sta si zbyt "ostro偶ny".

**Wnioski:**
- **Regularyzacja jest kluczowa:** Zar贸wno Dropout, jak i L2 znaczco poprawiy wyniki w por贸wnaniu do modelu bez regularyzacji (F1-score z 0.53 do ponad 0.60).
- **Optymalny poziom:** Istnieje "zoty rodek". Zbyt maa regularyzacja nie zapobiega przeuczeniu, a zbyt du偶a mo偶e "zdusi" model i uniemo偶liwi mu nauk.

### Eksperyment 5: Jaki styl nauki? (Optymalizatory)

Optymalizator to algorytm, kt贸ry decyduje, jak sie ma si uczy i modyfikowa swoje wagi. Por贸wnalimy trzy popularne: `Adam`, `SGD` i `RMSprop`.

![Por贸wnanie optymalizator贸w](results/nn_fig_05_optimizer_comparison.png)

> **Rysunek 5.** Por贸wnanie optymalizator贸w. `Adam` i `SGD` day najlepsze i bardzo zbli偶one wyniki, znacznie przewy偶szajc `RMSprop`.

**Wnioski:**
- **Adam i SGD wygrywaj:** `Adam`, czsto bdcy domylnym wyborem, okaza si bardzo skuteczny. Co ciekawe, klasyczny `SGD` z momentum dotrzymywa mu kroku, co pokazuje, 偶e nie zawsze najnowsze algorytmy s najlepsze.
- **Wyb贸r ma znaczenie:** `RMSprop` w tym przypadku wyra藕nie sobie nie poradzi, co dowodzi, 偶e wyb贸r optymalizatora jest wa偶n decyzj projektow.

---

## Fina: Najlepszy Model MLP vs Random Forest

Po serii eksperyment贸w, zebralimy najlepsze komponenty i zbudowalimy **optymalny model MLP**:

- **Architektura:** [128, 64] (rednia)
- **Aktywacja:** ReLU
- **Regularyzacja:** Dropout=0.3 + L2=0.01
- **Optymalizator:** Adam

Jak wypad w starciu z naszym mistrzem, Random Forest?

![MLP vs RF](results/nn_fig_06_mlp_vs_rf.png)

> **Rysunek 6.** Por贸wnanie kluczowych metryk dla najlepszych modeli MLP oraz modelu Random Forest (podwietlony na zielono).

### Tabela Por贸wnawcza (Top 10)

![Tabela podsumowujca](results/nn_fig_07_summary_table.png)

> **Rysunek 7.** Tabela z 10 najlepszymi modelami ze wszystkich eksperyment贸w. Na szczycie listy znajduje si Random Forest.

---

##  Ostateczne Wnioski

1.  **Random Forest Wygrywa! **
    - Mimo systematycznej optymalizacji, **偶aden z testowanych modeli MLP nie zdoa pokona modelu Random Forest**. Najlepszy MLP osign F1-score 0.6222, podczas gdy RF mia 0.6800.
    - Kluczowa r贸偶nica le偶y w metryce **Recall (Czuo)**. Random Forest osign fenomenalny wynik **89.5%**, co oznacza, 偶e wykry prawie 9 na 10 pacjent贸w z grupy ryzyka. Najlepszy MLP uzyska w tej metryce tylko 73.7%.

2.  **Sieci Neuronowe s Wra偶liwe i Wymagajce**
    - Eksperymenty pokazay, jak bardzo wyniki MLP zale偶 od architektury, regularyzacji i optymalizatora. Znalezienie dobrej konfiguracji wymagao wielu pr贸b.
    - Random Forest zadziaa wietnie "prosto z pudeka" z minimaln optymalizacj.

3.  **May Zbi贸r Danych to Wyzwanie dla MLP**
    - Sieci neuronowe s "godne danych". Na maym zbiorze (299 pr贸bek) ryzyko przeuczenia jest bardzo wysokie, co wymagao silnej regularyzacji (Dropout i L2). Prawdopodobnie na wikszym zbiorze danych MLP mogoby pokaza swoj prawdziw si.

4.  **Wnioski z Optymalizacji MLP:**
    - **Architektura:** Prostsze, pytsze sieci dziaay lepiej.
    - **Aktywacja:** `ReLU` i `ELU` s solidnym wyborem.
    - **Regularyzacja:** Jest **absolutnie kluczowa** na maych zbiorach danych.
    - **Optymalizator:** `Adam` jest bezpiecznym i skutecznym wyborem.

**Wniosek kocowy:** W tym konkretnym zadaniu, dla tego zbioru danych, klasyczny, dobrze zaimplementowany model **Random Forest okaza si lepszym narzdziem ni偶 sie neuronowa**. Jest prostszy, wymaga mniej strojenia i, co najwa偶niejsze, osign wy偶sz skuteczno, zwaszcza w kluczowej dla medycyny metryce Recall. To cenna lekcja, 偶e nie zawsze najnowsze i najbardziej zo偶one technologie s najlepszym rozwizaniem. 
