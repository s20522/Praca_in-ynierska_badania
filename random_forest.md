#  Przewodnik po modelu Random Forest dla Pocztkujcych

**Autor:** Heart Failure Research Team  
**Data:** 29 grudnia 2024  
**Cel:** Wyjanienie krok po kroku, jak zbudowa i oceni model Random Forest na przykadzie predykcji niewydolnoci serca.

---

## Wprowadzenie: Czym jest Random Forest (Las Losowy)?

Wyobra藕 sobie, 偶e chcesz podj wa偶n decyzj, na przykad, czy kupi dany samoch贸d. Zamiast pyta o opini jednego eksperta, pytasz setki r贸偶nych ekspert贸w. Ka偶dy z nich zwraca uwag na co innego: jeden na silnik, drugi na spalanie, trzeci na komfort. Na koniec zbierasz wszystkie opinie i podejmujesz decyzj na podstawie tego, co doradzia wikszo.

**Random Forest (Las Losowy)** dziaa dokadnie na tej samej zasadzie! To model uczenia maszynowego, kt贸ry skada si z wielu (setek, a nawet tysicy) prostszych modeli zwanych **drzewami decyzyjnymi**. Ka偶de drzewo "gosuje" na ostateczny wynik, a model jako cao wybiera odpowied藕, kt贸ra uzyskaa najwicej gos贸w. Dziki temu jest znacznie mdrzejszy i bardziej odporny na bdy ni偶 pojedyncze drzewo.

### Dlaczego Random Forest jest tak popularny?

- **Jest skuteczny:** Czsto osiga bardzo dobre wyniki bez skomplikowanej optymalizacji.
- **Jest odporny na bdy:** Dziki "gosowaniu" pojedyncze bdne drzewo nie psuje caego wyniku.
- **Jest wszechstronny:** Dziaa zar贸wno dla problem贸w klasyfikacji (jak nasz), jak i regresji.
- **M贸wi nam, co jest wa偶ne:** Potrafi oceni, kt贸re cechy miay najwikszy wpyw na jego decyzje (tzw. *feature importance*).

---

## Krok 1: Przygotowanie danych (Preprocessing)

Zanim zaczniemy budowa nasz "las", musimy przygotowa dla niego odpowiedni "teren".

### 1.1. Wyb贸r cech

Na podstawie naszej wczeniejszej analizy (EDA) oraz zalece z publikacji, wybralimy tylko **trzy najwa偶niejsze cechy**:

1.  `age` (wiek)
2.  `ejection_fraction` (frakcja wyrzutowa)
3.  `serum_creatinine` (kreatynina w surowicy)

**Dlaczego tylko trzy?** Czasami mniej znaczy wicej. Skupienie si na najwa偶niejszych cechach mo偶e prowadzi do prostszych i bardziej stabilnych modeli. Oczywicie, wykluczylimy cech `time` ze wzgldu na **target leakage**.

### 1.2. Podzia danych

Nasz zbi贸r danych (299 pacjent贸w) podzielilimy na dwie czci:

- **Zbi贸r treningowy (80% danych):** Na nim nasz model bdzie si "uczy".
- **Zbi贸r testowy (20% danych):** To zupenie nowe dane, kt贸rych model nigdy nie widzia. U偶yjemy ich na samym kocu, aby sprawdzi, jak dobrze model sobie radzi w "prawdziwym wiecie".

U偶ylimy podziau **stratyfikowanego**, co oznacza, 偶e w obu zbiorach zachowalimy takie same proporcje pacjent贸w zmarych i 偶yjcych. To bardzo wa偶ne przy niezbalansowanych danych!

### 1.3. Normalizacja danych

Nasze cechy maj r贸偶ne skale (wiek: 40-95, kreatynina: 0.5-9.4). Aby model nie faworyzowa cech o wikszych wartociach, musimy je "sprowadzi do wsp贸lnego mianownika". U偶ylimy **standaryzacji**, kt贸ra przeksztaca dane tak, aby miay redni r贸wn 0 i odchylenie standardowe r贸wne 1.

---

## Krok 2: Budowa i optymalizacja modelu

Teraz czas na najciekawsz cz - budow naszego lasu!

### Pojcie: Hiperparametry

Hiperparametry to "pokrta" i "suwaki", kt贸re mo偶emy regulowa, aby dostroi nasz model. W przypadku Random Forest s to na przykad:

- `n_estimators`: Liczba drzew w lesie.
- `max_depth`: Maksymalna gboko ka偶dego drzewa.
- `min_samples_split`: Minimalna liczba pr贸bek potrzebna do podziau wza w drzewie.

### 2.1. Optymalizacja - Randomized Search CV

Jak znale藕 najlepsze ustawienia tych "pokrte"? Rczne testowanie byoby bardzo czasochonne. Dlatego u偶ylimy techniki **Randomized Search CV**. Dziaa ona w nastpujcy spos贸b:

1.  Definiujemy zakres mo偶liwych wartoci dla ka偶dego hiperparametru.
2.  Algorytm losowo wybiera 100 r贸偶nych kombinacji tych ustawie.
3.  Dla ka偶dej kombinacji trenuje model i ocenia go za pomoc **walidacji krzy偶owej (cross-validation)**.

### Pojcie: Walidacja krzy偶owa (Cross-Validation)

To technika, kt贸ra pozwala rzetelnie oceni model. Zamiast jednego podziau na zbi贸r treningowy i testowy, robimy to wielokrotnie. W naszym przypadku u偶ylimy **5-krotnej walidacji krzy偶owej**: zbi贸r treningowy jest dzielony na 5 czci. Model jest trenowany na 4 czciach, a testowany na pitej. Proces jest powtarzany 5 razy, tak aby ka偶da cz bya raz zbiorem testowym. Na koniec uredniamy wyniki.

### 2.2. Najlepsze znalezione parametry

Po przeszukaniu 100 kombinacji, Randomized Search znalaz dla nas optymalne ustawienia:

- **Liczba drzew (`n_estimators`):** 100
- **Minimalna liczba pr贸bek do podziau (`min_samples_split`):** 5
- **Minimalna liczba pr贸bek w liciu (`min_samples_leaf`):** 8
- **Waga klas (`class_weight`):** `balanced` (to wa偶ne - m贸wi modelowi, aby bardziej "przejmowa si" bdami na mniejszej klasie, czyli zmarych pacjentach)

---

## Krok 3: Ewaluacja modelu - Jak dobry jest nasz las?

Teraz, gdy mamy ju偶 wytrenowany i zoptymalizowany model, czas sprawdzi, jak dobrze sobie radzi na zbiorze testowym, kt贸rego nigdy wczeniej nie widzia.

### 3.1. Metryki oceny - Czym mierzymy sukces?

Sama **dokadno (accuracy)** to za mao przy niezbalansowanych danych. Dlatego u偶ylimy kilku metryk:

- **Accuracy (Dokadno):** Jaki procent wszystkich predykcji by poprawny.
- **Precision (Precyzja):** Spor贸d wszystkich pacjent贸w, kt贸rych model oznaczy jako "zmarli", ilu faktycznie zmaro? (Wa偶ne, aby nie straszy zdrowych pacjent贸w).
- **Recall (Czuo):** Spor贸d wszystkich pacjent贸w, kt贸rzy faktycznie zmarli, ilu model poprawnie zidentyfikowa? (Wa偶ne, aby nie przegapi pacjent贸w wysokiego ryzyka).
- **F1-score:** rednia harmoniczna precyzji i czuoci. Dobry kompromis midzy obiema metrykami.
- **AUC-ROC:** Miara zdolnoci modelu do odr贸偶niania klasy pozytywnej od negatywnej.

### 3.2. Wyniki na zbiorze testowym

![Podsumowanie metryk](results/rf_fig_05_metrics_summary.png)

> **Rysunek 1.** Podsumowanie metryk oceny modelu Random Forest na zbiorze testowym.

**Kluczowe wyniki:**

- **F1-score:** 0.6800 (68.0%)
- **Recall (Czuo):** 0.8947 (89.5%) - **bardzo wysoki!**
- **Precision (Precyzja):** 0.5484 (54.8%)
- **AUC-ROC:** 0.7689

**Interpretacja:**
Nasz model ma **bardzo wysok czuo (Recall)**, co oznacza, 偶e jest wietny w **wykrywaniu pacjent贸w, kt贸rzy faktycznie s zagro偶eni zgonem** (wykry prawie 90% z nich!). Jego precyzja jest ni偶sza, co oznacza, 偶e czasami mylnie oznacza zdrowych pacjent贸w jako zagro偶onych. W medycynie jest to jednak lepszy kompromis - wolimy faszywy alarm ni偶 przegapienie prawdziwego zagro偶enia.

### 3.3. Macierz pomyek

To tabela, kt贸ra pokazuje, gdzie model si myli.

![Macierz pomyek](results/rf_fig_01_confusion_matrix.png)

> **Rysunek 2.** Macierz pomyek. Pokazuje, ile razy model poprawnie lub bdnie sklasyfikowa pacjent贸w.

**Interpretacja:**

- **True Positive (TP): 17** - Model poprawnie zidentyfikowa 17 pacjent贸w, kt贸rzy zmarli.
- **False Negative (FN): 2** - Model **przegapi** tylko 2 pacjent贸w, kt贸rzy zmarli (bardzo dobry wynik!).
- **False Positive (FP): 14** - Model mylnie oznaczy 14 pacjent贸w jako zagro偶onych, chocia偶 prze偶yli.
- **True Negative (TN): 27** - Model poprawnie zidentyfikowa 27 pacjent贸w, kt贸rzy prze偶yli.

### 3.4. Krzywa ROC i Krzywa Precision-Recall

To zaawansowane wizualizacje, kt贸re pokazuj, jak model radzi sobie przy r贸偶nych progach decyzyjnych.

| Krzywa ROC | Krzywa Precision-Recall |
| :---: | :---: |
| ![Krzywa ROC](results/rf_fig_02_roc_curve.png) | ![Krzywa Precision-Recall](results/rf_fig_03_precision_recall_curve.png) |

> **Rysunek 3 i 4.** Krzywa ROC (lewa) i Krzywa Precision-Recall (prawa). Im wy偶ej i bardziej w lewo znajduje si krzywa, tym lepszy model.

**Interpretacja:**
- **Krzywa ROC (AUC = 0.7689):** Warto AUC znacznie powy偶ej 0.5 (losowy klasyfikator) pokazuje, 偶e model ma dobr zdolno do odr贸偶niania obu klas.
- **Krzywa Precision-Recall (AUC = 0.6961):** Warto AUC znacznie powy偶ej linii bazowej (proporcja klasy pozytywnej) potwierdza, 偶e model jest u偶yteczny w kontekcie niezbalansowanych danych.

---

## Krok 4: Co jest wa偶ne dla modelu?

Random Forest potrafi nam powiedzie, kt贸re cechy miay najwikszy wpyw na jego decyzje.

### Wyniki

![Wa偶no cech](results/rf_fig_04_feature_importance.png)

> **Rysunek 5.** Wa偶no cech w modelu Random Forest.

**Interpretacja:**

1.  **Kreatynina w surowicy (46.07%):** Zdecydowanie najwa偶niejsza cecha. Poziom kreatyniny mia najwikszy wpyw na decyzje modelu.
2.  **Frakcja wyrzutowa (33.76%):** Druga co do wa偶noci cecha.
3.  **Wiek (20.17%):** Najmniej wa偶na z tej tr贸jki, ale wci偶 istotna.

To potwierdza nasze wnioski z EDA - te trzy cechy s kluczowe!

---

## Podsumowanie i por贸wnanie z publikacj

### Co osignlimy?

- Zbudowalimy i zoptymalizowalimy model Random Forest, kt贸ry z du偶 skutecznoci potrafi identyfikowa pacjent贸w zagro偶onych zgonem.
- Model osign **bardzo wysok czuo (Recall = 89.5%)**, co jest kluczowe w zastosowaniach medycznych.
- Potwierdzilimy, 偶e cechy `serum_creatinine`, `ejection_fraction` i `age` s najwa偶niejszymi predyktorami.

### Por贸wnanie z publikacj

Publikacja bazowa nie podaje szczeg贸owych wynik贸w dla modelu Random Forest, ale dla modelu SVM uzyskaa F1-score na poziomie 88.37%. Nasz model osign F1-score na poziomie 68.00%.

**Dlaczego wyniki mog si r贸偶ni?**

- **Inny dob贸r cech:** My u偶ylimy tylko 3 cech, zgodnie z zaleceniami z analizy Coksa. Autorzy publikacji mogli u偶y innego zestawu.
- **Inny preprocessing:** R贸偶nice w sposobie normalizacji czy obsugi danych.
- **Inne hiperparametry:** Nasza optymalizacja moga prowadzi do innego zestawu parametr贸w.

Naszym celem bya **reprodukcja metodyki**, a nie lepe kopiowanie wynik贸w. Osignlimy model, kt贸ry jest **klinicznie u偶yteczny** (wysoki Recall) i oparty na solidnych podstawach metodologicznych.

### Co dalej?

Nastpnym krokiem bdzie przetestowanie innych modeli (np. SVM, XGBoost) oraz bardziej zaawansowanych architektur, takich jak sieci neuronowe, aby sprawdzi, czy uda nam si jeszcze bardziej poprawi wyniki, zachowujc przy tym wysok czuo modelu.
