#  Przewodnik po Eksperymentach z In偶ynieri Cech (Feature Engineering)

**Autor:** Heart Failure Research Team  
**Data:** 29 grudnia 2024  
**Cel:** Wyjanienie, jak za pomoc in偶ynierii cech mo偶na pr贸bowa ulepszy model predykcyjny, na przykadzie Random Forest.

---

## Wprowadzenie: Czym jest In偶ynieria Cech?

Wyobra藕 sobie, 偶e jeste detektywem, a dane to Twoje dowody. Czasami surowe dowody (np. odcisk buta) nie m贸wi wszystkiego. Ale jeli poczysz je z innymi informacjami (np. z rozmiarem buta, rodzajem bota na podeszwie), mo偶esz stworzy znacznie peniejszy obraz i wycign lepsze wnioski.

**In偶ynieria cech (Feature Engineering)** to wanie taka praca detektywistyczna na danych. To proces **tworzenia nowych cech (zmiennych)** z ju偶 istniejcych, aby pom贸c modelom uczenia maszynowego lepiej "zrozumie" problem i dokonywa trafniejszych predykcji. To jedna z najwa偶niejszych i najbardziej kreatywnych czci pracy analityka danych.

### Dlaczego to robimy?

- **Aby odkry ukryte zale偶noci:** Czasami proste poczenie dw贸ch cech (np. wiek * poziom kreatyniny) m贸wi wicej ni偶 ka偶da z nich osobno.
- **Aby uproci problem dla modelu:** Przeksztacenie cech cigych w kategorie (np. "niski", "redni", "wysoki") mo偶e pom贸c modelom drzewiastym.
- **Aby poprawi wyniki:** Dobrze zaprojektowane cechy mog znaczco zwikszy skuteczno modelu.

W tej czci pracy przeprowadzilimy seri eksperyment贸w, aby sprawdzi, czy in偶ynieria cech pomo偶e nam ulepszy nasz bazowy model Random Forest.

---

## Model Bazowy (Baseline) - Nasz Punkt Odniesienia

Zanim zaczniemy eksperymenty, musimy mie punkt odniesienia, do kt贸rego bdziemy por贸wnywa wyniki. Naszym modelem bazowym jest ten sam model Random Forest, kt贸ry zbudowalimy wczeniej:

- **Cechy:** `age`, `ejection_fraction`, `serum_creatinine` (surowe wartoci)
- **Normalizacja:** `StandardScaler`

**Wyniki modelu bazowego:**

| Metryka | Warto |
|---|---|
| **F1-score** | **0.6800** |
| **Recall (Czuo)** | **0.8947** |
| **Precision (Precyzja)** | 0.5484 |
| **AUC-ROC** | 0.7689 |

To s wyniki, kt贸re bdziemy pr贸bowali pobi!

---

## Eksperyment 1: Dyskretyzacja - Dzielenie na Kategorie

### Co to jest?

**Dyskretyzacja** to proces zamiany cech cigych (np. wiek od 40 do 95) na cechy kategoryczne (np. "mody", "w rednim wieku", "starszy"). Zamiast patrze na dokadn warto, grupujemy j w przedziay.

### Jak to zrobilimy?

Podzielilimy nasze trzy g贸wne cechy na kategorie oparte na progach klinicznych:

- **Wiek (`age`):**
  - Kategoria 0: [40-60] (modszy)
  - Kategoria 1: [60-80] (redni)
  - Kategoria 2: [80-95] (starszy)
- **Frakcja wyrzutowa (`ejection_fraction`):**
  - Kategoria 0: <30% (ci偶ka dysfunkcja)
  - Kategoria 1: 30-45% (umiarkowana dysfunkcja)
  - Kategoria 2: >45% (lekka dysfunkcja/norma)
- **Kreatynina (`serum_creatinine`):**
  - Kategoria 0: <1.2 mg/dL (norma)
  - Kategoria 1: 1.2-3.0 mg/dL (podwy偶szony)
  - Kategoria 2: >3.0 mg/dL (wysoki)

### Wyniki

| Metryka | Wynik | Zmiana vs Baseline |
|---|---|---|
| **F1-score** | 0.5106 | **-25%**  |
| **Recall** | 0.6316 | **-29%**  |
| **AUC-ROC** | 0.6694 | **-13%**  |

### Wnioski

**Dyskretyzacja okazaa si bardzo zym pomysem!** Wyniki drastycznie spady. Dlaczego?

- **Utrata informacji:** Zamieniajc dokadn warto (np. wiek 79) na kategori ("redni"), tracimy precyzj. Dla modelu nie ma r贸偶nicy midzy pacjentem w wieku 61 a 79 lat, co jest nieprawd.
- **Modele drzewiaste same to robi:** Random Forest naturalnie dzieli dane na progi. Rczna dyskretyzacja bya niepotrzebna i tylko zaszkodzia.

**Lekcja:** Nie zawsze to, co wydaje si intuicyjne (grupowanie), jest dobre dla modelu.

---

## Eksperyment 2: Cechy Interakcyjne - czenie Dowod贸w

### Co to jest?

Tworzenie **cech interakcyjnych** polega na czeniu dw贸ch lub wicej cech, najczciej przez ich pomno偶enie. Ma to na celu uchwycenie **efektu synergii**, gdzie poczony wpyw dw贸ch cech jest wikszy ni偶 suma ich pojedynczych wpyw贸w.

### Jak to zrobilimy?

Do naszych 3 bazowych cech dodalimy 3 nowe, reprezentujce interakcje:

1.  `age_x_creat`: Wiek  Kreatynina (ryzyko zwizane z wiekiem i funkcj nerek)
2.  `ef_x_sodium`: Frakcja wyrzutowa  S贸d (funkcja serca i r贸wnowaga elektrolitowa)
3.  `age_x_ef`: Wiek  Frakcja wyrzutowa (rokowanie u pacjent贸w w r贸偶nym wieku z podobn funkcj serca)

### Wyniki

| Metryka | Wynik | Zmiana vs Baseline |
|---|---|---|
| **F1-score** | 0.6667 | -2.0% |
| **Recall** | 0.8421 | -5.9% |
| **AUC-ROC** | 0.7522 | -2.2% |

### Wnioski

Dodanie cech interakcyjnych **nieznacznie pogorszyo wyniki**. Co ciekawe, analiza wa偶noci cech pokazaa, 偶e **nowe cechy interakcyjne stay si znacznie wa偶niejsze ni偶 ich oryginalne skadowe!**

- `age_x_creat`: 43.6% wa偶noci
- `ef_x_sodium`: 29.1% wa偶noci
- `age_x_ef`: 11.9% wa偶noci

Oznacza to, 偶e model uzna poczone efekty za bardziej predykcyjne. Mimo to, og贸lna skuteczno modelu spada. Prawdopodobnie dodanie nowych cech wprowadzio dodatkowy "szum", z kt贸rym model sobie nie poradzi, lub oryginalne cechy ju偶 wystarczajco dobrze opisyway problem.

---

## Eksperyment 3: Inna Normalizacja - MinMaxScaler

### Co to jest?

Sprawdzilimy, czy zmiana metody skalowania danych wpynie na wynik. Zamiast `StandardScaler` (rednia=0, odch. std.=1), u偶ylimy `MinMaxScaler`, kt贸ry skaluje dane do zakresu **[0, 1]**.

### Wyniki

| Metryka | Wynik | Zmiana vs Baseline |
|---|---|---|
| **F1-score** | 0.6800 | **0%** (bez zmian) |
| **Recall** | 0.8947 | **0%** (bez zmian) |
| **AUC-ROC** | 0.7689 | **0%** (bez zmian) |

### Wnioski

**Brak jakichkolwiek zmian.** To potwierdza teori, 偶e **Random Forest nie jest wra偶liwy na skal cech**. Zar贸wno standaryzacja, jak i normalizacja day identyczne wyniki, poniewa偶 nie zmieniaj one kolejnoci wartoci, a jedynie ich skal, co dla modeli drzewiastych nie ma znaczenia.

---

## Eksperyment 4: Wszystkie Cechy + Interakcje

### Co to jest?

Postanowilimy p贸j na cao i da modelowi **wszystkie dostpne cechy** (opr贸cz `time`), a tak偶e doda do nich nasze cechy interakcyjne. W sumie model otrzyma **14 cech**.

### Wyniki

| Metryka | Wynik | Zmiana vs Baseline |
|---|---|---|
| **F1-score** | 0.6531 | -4.0% |
| **Recall** | 0.8421 | -5.9% |
| **AUC-ROC** | 0.7240 | -5.8% |

### Wnioski

**Wicej wcale nie znaczy lepiej!** Mimo dostarczenia znacznie wikszej iloci informacji, model poradzi sobie gorzej ni偶 model bazowy z tylko 3 cechami. Jest to zjawisko znane jako **"kltwa wymiarowoci"** - zbyt wiele cech (zwaszcza tych mao istotnych) mo偶e wprowadzi szum i utrudni modelowi znalezienie kluczowych wzorc贸w.

Analiza wa偶noci cech ponownie pokazaa dominacj cech interakcyjnych, ale og贸lny wynik by sabszy.

---

## Podsumowanie i Wizualizacje

Po przeprowadzeniu wszystkich eksperyment贸w, czas na podsumowanie.

### Tabela Por贸wnawcza

![Tabela podsumowujca](results/fe_fig_05_summary_table.png)

> **Rysunek 1.** Tabela por贸wnujca wyniki wszystkich eksperyment贸w. Zielonym kolorem zaznaczono najlepsze wyniki w ka偶dej kolumnie.

### Por贸wnanie Metryk

![Por贸wnanie metryk](results/fe_fig_01_metrics_comparison.png)

> **Rysunek 2.** Wykresy supkowe por贸wnujce pi kluczowych metryk dla ka偶dego z eksperyment贸w.

### Por贸wnanie F1-score i Recall

![Por贸wnanie F1 i Recall](results/fe_fig_03_f1_recall_comparison.png)

> **Rysunek 3.** Por贸wnanie dw贸ch najwa偶niejszych metryk: F1-score (og贸lna jako) i Recall (zdolno do wykrywania zagro偶e). Wida, 偶e model bazowy ma najwy偶szy Recall.

### Por贸wnanie Krzywych ROC

![Por贸wnanie ROC](results/fe_fig_02_roc_comparison.png)

> **Rysunek 4.** Krzywe ROC dla wszystkich modeli. Krzywa dla modelu bazowego (niebieska) znajduje si najwy偶ej, co potwierdza jego najlepsz zdolno do rozr贸偶niania klas.

---

##  G贸wne Wnioski z Eksperyment贸w

1.  **Model Bazowy jest Najlepszy:** 呕adna z pr贸b in偶ynierii cech **nie poprawia** wynik贸w modelu bazowego. Wrcz przeciwnie, wikszo z nich pogorszya jego skuteczno.

2.  **Mniej znaczy Wicej:** Najprostszy model, oparty na zaledwie trzech, ale za to najwa偶niejszych cechach, okaza si najskuteczniejszy. To wa偶na lekcja, 偶e kluczem jest **jako, a nie ilo** cech.

3.  **Dyskretyzacja jest Ryzykowna:** Rczne grupowanie danych cigych mo偶e prowadzi do znacznej utraty informacji i jest niepotrzebne w przypadku modeli drzewiastych.

4.  **Interakcje s Ciekawe, ale nie Zawsze Pomocne:** Mimo 偶e model uzna cechy interakcyjne za bardzo wa偶ne, nie przeo偶yo si to na lepsz og贸ln skuteczno. Prawdopodobnie wprowadziy one zbyt du偶 zo偶ono.

5.  **Random Forest jest Odporny:** Eksperyment z `MinMaxScaler` potwierdzi, 偶e Random Forest jest odporny na skal cech, co jest jedn z jego du偶ych zalet.

**Wniosek kocowy:** W przypadku tego zbioru danych i modelu Random Forest, staranna selekcja najwa偶niejszych, surowych cech okazaa si znacznie lepsz strategi ni偶 zaawansowana in偶ynieria cech. Nasz oryginalny model bazowy pozostaje mistrzem!  **mistrzem**! **!
